---
title: 将来予測の技術＜M5＞　事後課題レポート例
date: 2015-12-24
author: 西山
---

```{r setup,message=F,warning=F}
library(forecast)
```

# 自動車販売台数データ

##　最も簡単・効率的な進め方

最も簡単な進め方は、パッケージ"forecast"のauto.arimaを用いて、診断ステップ抜きで ---理屈としては最良の予測モデルを選んでいるので診断を改めて行ってもムダであるとも言える---予測値を求める。こんな簡便にして効率的な方法をとる機会が、実は日常的な予測作業では非常に多い（最良のソフトウェアを利用して時間を節約せよ！）

### データ入力

作業ディレクトリーを変更してから以下のように分析の準備をする。

```{r read_car}
data0 <- read.csv(file="Car-Japan-1993Q1-2015Q2.csv")
head(data0)
sale <- data0$sale
sale <- ts(sale,freq=4,start=c(1993,1))
plot(sale)
```

図を見ると季節性があるような印象である。とはいえ、季節成分はそれほど明瞭ではなく、乗法モデルを当てはめる必要性もないと見られる。2009年前後、2011年前後の落ち込みは言うまでもなくリーマン危機と東日本大震災である。この二つはトレンドや循環とは異なる巨大なノイズである。

### 予測モデル推定と予測

最速の方法で行こう。

```{r autoarima}
kekka <- auto.arima(sale)
yosoku <- forecast(kekka,h=4)
plot(yosoku)
```

パッケージ"forecast"の自動探索を利用すると、推定から予測までわずか２ステップである。推定された予測モデルの確認すら行っていない。

日常ルーティンの事前予測はこのように効率的に行いつつ、新たな実績が事前予測を上回ったか、下回ったかを確認する。通常はこんな風に予測作業を日常のプロセスの一環として行っている所が多いのではないだろうか。

予測数値を示しておこう。

```{r dis_yosoku}
yosoku
```

##　丁寧な進め方

通常の予測作業は上のように効率的に行うことが大切である。とはいえ、使っている予測モデルの性能を知っておくことも重要である。このデータについては、少し丁寧に検証作業をしておくことにしよう。

###　学習データの検討

予測性能の検証においては、まずデータを学習データとテストデータに分けるのが定石である。

ここでは最後の1年間を除いた2014年第2四半期までのデータを学習データ、2014年第3四半期から翌年第2四半期までのデータをテストデータとする。

```{r split_data}
sale1 <- window(sale,end=c(2014,2))
sale2 <- window(sale,start=c(2014,3))
```

#### （偏）自己相関図

学習データの変化の特徴をまとめよう。

```{r acf_sale1}
acf(sale1)
pacf(sale1)
```

販売台数データには季節成分が混じっている印象があったが、自己相関図をみると、いわゆる1年周期ごとにスパイクがたつ「鋸型」の認定するには少し弱い。トレンドがある風でもあったが、「高止まり型」とも言えないようである。偏自己相関図のラグ１（左端）は概ね0.6であり、この程度では差をとらなくとも良さそうである。

季節成分は無視、トレンドもないと判定するなら、上の二つの図から予測モデルを決めなければならない。偏自己相関図をカット型にすれば簡単なのだが、スパイクは何本あるだろうか。ラグ１だけを認めるか、ラグ５，６も認めるか、ラグ９まで認めるかである。自己相関図は減衰型にしてよさそうなので、偏自己相関図はカット型として、自己回帰型でいくことにする。

（注）

差をとらずに自己回帰型でよいなら、コマンドとしてはまずarを使って見当をつけておくとよいだろう。ここでは省略する。

#### 推定と診断

```{r est_sale}
kekka1 <- Arima(sale1,order=c(1,0,0))
kekka2 <- Arima(sale1,order=c(6,0,0))
kekka3 <- Arima(sale1,order=c(9,0,0))
```

上の三つの中でAICが最も小さいのはkekka3である。この診断図をみよう。

```{r kekka3_tsdiag}
tsdiag(kekka3)
```

図を見ると、予測誤差はランダムに出ており、自己相関は残っていない。そこで予測モデル"kekka3"（＝9次の自己回帰）を用いてテストデータを予測してみよう。

####　予測と誤差評価

```{r kekka3_yosoku}
yosoku3 <- forecast(kekka3,h=4)
plot(yosoku3)
points(sale2,pch=20,col="red")
```

2014年第3四半期以降1年間の実績を赤い点で示している。事前予測値と比べれば、特に2015年第2四半期が大きく下ぶれしたことが分かる --- このことは2015年第1四半期までの実績を織り込んだ1期先予測の話しとは異なる。

どうやら2014年後半から自動車販売は弱めに推移し、特に2015年度春から夏にかけては弱さが顕在化した。そんな風に読める。


予測モデル"kekka3"の予測誤差を評価しておこう。

```{r gosa_kekka3}
gosa3 <- yosoku3$mean-sale2
gosa.jijou.mean <- mean(gosa3^2)
rmse <- sqrt(gosa.jijou.mean)
rmse
rmse/mean(sale2)
```

テストデータ期間中の予測誤差は平均で13万9千台、平均台数に対する比率にすると概ね6%程度の標準誤差である。

もし学習データで自動探索をかけるとどうなるか？

```{r auto_sale1}
kekka.auto <- auto.arima(sale1)
yosoku.auto <- forecast(kekka.auto,h=4)
plot(yosoku.auto)
```

自動探索は（ものすごく）複雑なモデルを提案してきている---全データ"sale"を対象とするときは別の結果だった。

データをどう切り取るかによって当てはめられる予測モデルが違うのは、二つの大きなショック（リーマン危機、東日本大震災）を**環境変化**ではなく、そのままばらつき一定の不規則変動として予測モデルを決めようとしていることに原因がある。外部要因、環境変化をどう含めるかについては次回授業でとりあげる予定である。

二つの予測モデルのAICを確認しておこう。

```{r aic_hikaku}
kekka3
kekka.auto
```

自動探索"auto.arima"は、同じデータに対して最も予測誤差が小さくなる（と思われる）予測モデルを提案する。実際、学習データ"sale1"に対しては自動探索の結果のほうがAICは小さい。

しかし「AICが小さい」と言うのは、誤差は小さい（と思われる）ということであって、実際に時間が経過したあと、AICが小さい方が本当に誤差が小さいはずだと言っているわけではない。

事前の思惑と事後評価は別である。故に、事前段階で**検証**をしっかりしておくことも**効率化**と同じく大事な事柄である。


```{r gosa_auto}
gosa.auto <- yosoku.auto$mean-sale2
rmse <- sqrt(mean(gosa.auto^2))
rmse
rmse/mean(sale2)
```

自動探索で得られた予測モデルは、学習データについては確かにAICが小さいが、テストデータの事前予測値と実績値を比べると、事後的な誤差は平均に対して7.6%に達しむしろ大きく出てしまった。

どんな（高級な）予測用ソフトウエアでもそうなのだが、AIC等のモデル選択基準で自動探索を行う場合、しばしば学習データのうちの細かい部分を拾って予測モデルをつくってしまうことがある。これを<font color="red">**過剰学習**</font>という。

以上のように、将来予測で気をつける点は三つある。

1. ソフトウェアの機能を活用して効率的に作業する。

2. 予測モデルの自動探索結果が、事後的にもベストであるとは限らない。

3. 特に、大きなノイズが発生して間がない時期に予測を行うときは、幾つかの予測モデルで予測性能を比較しておくべきである。

###　本予測（1年間）

本予測はどの予測モデルで行うべきだろうか？

丁寧な作業の結果、AICを最小にする自動探索結果の予測性能が本当に高いのか確信が持てない。そんな迷いもある。そこで、最初に行った予測とは別に"yosoku3"による計算結果もみておこう。

この予測モデル"kekka3"を全データでアップデートして本予測を行ってみる。

```{r yosoku3_alldata}
kekka3.sale <- Arima(sale,order=c(9,0,0))
yosoku3.sale <- forecast(kekka3.sale,h=4)
plot(yosoku3.sale)
```

一番最初に示した自動探索ではデータ全体から下降トレンド(drift)を検出している。上の"yosoku3"のアップデートではトレンドは入れていない。

この違いもあって、自動探索結果による予測の方が弱めである。弱めの予測を採用しておくか、強めの予測をとるか。この選択は、予測技術の解というよりよ、どんな予測ミスをより一層懸念するか。この点の考察によるものである。

いずれにしても、将来予測は将来に関するものである。とはいえ、良い予測モデルは多くあるわけではない。

#　航空旅客数データ

##　うまく行かない自動探索

モジュール３の事後課題でとりあげた航空旅客数データはサンプルデータとしては有名なデータである --- （実は）扱いにくいデータとしても有名である。

まず自動探索でサクサクと作業を進めることにしよう。

```{r read_pas}
data1 <- read.csv(file="passenger.csv")
head(data1)
pas <- data1$x
pas <- ts(pas,freq=12,start=c(1949,1))
plot(pas)
```

今度のデータは季節成分が明瞭であり、かつバラツキが拡大しているので乗法モデルを当てはめるのが適切である。

```{r pas_to_log}
log.pas <- log(pas)
plot(log.pas)
```

対数をとると、季節成分のばらつきが概ね均一化される。

あとは自動探索をすればよい。まず保存せず結果だけを見よう。

```{r auto_log_pas}
auto.arima(log.pas)
```

ここで警告が出る。"unable to fit final model ..."というのは最適な予測モデルが見つからないという意味である。中間結果のAICは途中結果として表示されている。

いずれにしても、この途中結果は使えない。

ここでauto.arimaコマンドの探索方式を修正する指示をして、何とか最適な予測モデルを探し出すように工夫するというのが直接的解決法なのであるが、この進め方は奨励しない。『これでは自動探索の意味がなくなる』。これが理由である。

自動探索でサクサクといかない場合はオーソドックスにやればよい。


##　ボックス・ジェンキンズ法の手順に沿う

自動探索がうまく作動しないことは時にあることである。やはり変化の特徴をグラフから吟味する方法だけは知っておくとよい。

###　同定

そこで対数をとった後の旅客数log.pasについて変動パターンを吟味する。

```{r acf_logpas}
acf(log.pas,lag.max=48)
pacf(log.pas,lag.max=48)
```

自己相関図は高止まり型。かつ1年（12カ月）ごとに比較的高いスパイクがたっている鋸型の形をしている。更に、偏自己相関図のラグ１がほぼ1である。故に、差をとって調べることにする。

その差のとり方であるが、単なる前月差では季節性が残ってしまうので前年同月差をとることにする。対数をとって前年同月差をとる、ということは元の航空旅客数について前年同月比増減率をみることとほぼ同じである。

```{r acf_dlog_pas}
acf(diff(log.pas,12),lag.max=48)
pacf(diff(log.pas,12),lag.max=48)
```

自己相関図は印象として減衰型である。となると、偏自己相関図がカット型であれば自己回帰を当てはめるわけである。その偏自己相関図だが、減衰型ではないようである。ではスパイクを何本まで認めるか？左端の1本は明瞭である。あとは、ラｸﾞ１０、ラグ１３に比較的高いスパイクがある。

故に三つの自己回帰モデルを推定して、選択はAICをみて決めることにする。季節対応で1回だけ前年同月差をとっている点に注意して以下のようにする。

更に、データ全体で増加トレンドが明瞭である。include.driftをTRUEにするべきか、それは必要ないか。これもAICで決めるとよい。

###　推定


```{r est_logpas}
model1 <- Arima(log.pas,order=c(1,0,0),seasonal=c(0,1,0))
model1d <- Arima(log.pas,order=c(1,0,0),seasonal=c(0,1,0),include.drift=T)
model2 <- Arima(log.pas,order=c(10,0,0),seasonal=c(0,1,0))
model2d <- Arima(log.pas,order=c(10,0,0),seasonal=c(0,1,0),include.drift=T)
model3 <- Arima(log.pas,order=c(13,0,0),seasonal=c(0,1,0))
model3d <- Arima(log.pas,order=c(13,0,0),seasonal=c(0,1,0),include.drift=T)
```

順に上の結果を表示させて、特にAICを見ていけばよいわけであるが、全て表示させると長くなるので、結果のAICだけを表示させることにしよう。names(model1)とすると、結果の中に"aic"という名前があるので、これがaicだと見当がつく。


```{r disp_aic_logpas}
model1$aic
model1d$aic
model2$aic
model2d$aic
model3$aic
model3d$aic
```

AICが最小になる予測モデルは"model3"である --- 増加トレンドがあるのにドリフトを含めないモデルが最良とは…？最初は不思議に思われるだろうが、実際に旅客数の前年比"diff(log.pas,12)"の図を描いてみれば、前年比の平均は小数値で0.12程度であり、毎月の前年比のばらつきをみると、その平均が本当にプラスかどうか（これだけのデータから）断定はできない、と。ここはソフトウェアの判断を信頼することにしよう。

###　診断

診断もしておこう。

```{r tsdiag_logpas}
tsdiag(model3)
```

予測誤差はランダムに出ており問題なし。


###　予測

今回は大きなショックがある一時期に発生したというデータではないように見受けられる。故に、学習データ・テストデータの別を設けて予測性能を検討する作業は省略する。

```{r yosoku_logpas}
fc3 <- forecast(model3,h=12)
plot(fc3)
```

図をみると、想定される予測誤差もそれほど大きくはないようである。

### 対数を元の旅客数に戻す。

上で得られた結果は対数ベースの予測値である。これを元の旅客数ベースに戻す方が見やすいはずだ。

対数はlogで、対数を元に戻すには指数関数expを使う。ここでは中位予測だけを旅客数にしよう。

```{r to_exp_logpas}
pas.fc3 <- exp(fc3$mean)
pas.fc3
ts.plot(pas,pas.fc3,lty=c(1,2),col=c(1,2))
```



